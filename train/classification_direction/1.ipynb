{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_root = '../../data/classification_direction'\n",
    "train_root = '../../data/classification_direction/train'\n",
    "val_root = '../../data/classification_direction/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from torchvision.datasets import ImageFolder\n",
    "\n",
    "# def create_dir_structure(root_path, classes):\n",
    "#     for cls in classes:\n",
    "#         os.makedirs(os.path.join(root_path, cls), exist_ok=True)\n",
    "\n",
    "# def copy_files(file_paths, source_root, target_root):\n",
    "#     for file_path in file_paths:\n",
    "#         class_name = os.path.basename(os.path.dirname(file_path))\n",
    "#         target_path = os.path.join(target_root, class_name, os.path.basename(file_path))\n",
    "#         shutil.copy2(file_path, target_path)\n",
    "\n",
    "# # Загрузка исходного датасета\n",
    "# dataset = ImageFolder(root=source_root)\n",
    "# class_names = dataset.classes\n",
    "\n",
    "# # Определим количество данных для тренировки и валидации\n",
    "# train_ratio = 0.8\n",
    "# total_size = len(dataset)\n",
    "# train_size = int(total_size * train_ratio)\n",
    "# val_size = total_size - train_size\n",
    "\n",
    "# # Перемешаем данные и разделим их\n",
    "# indices = list(range(total_size))\n",
    "# random.shuffle(indices)\n",
    "# train_indices, val_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "# train_files = [dataset.imgs[idx][0] for idx in train_indices]\n",
    "# val_files = [dataset.imgs[idx][0] for idx in val_indices]\n",
    "\n",
    "# # Создадим структуру папок для тренировочных и валидационных данных\n",
    "# create_dir_structure(train_root, class_names)\n",
    "# create_dir_structure(val_root, class_names)\n",
    "\n",
    "# # Скопируем файлы в соответствующие папки\n",
    "# copy_files(train_files, source_root, train_root)\n",
    "# copy_files(val_files, source_root, val_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 3\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформации для данных\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.04),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "train_dataset = datasets.ImageFolder(root=train_root, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(root=val_root, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmitrii/anaconda3/envs/venv_ilona/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dmitrii/anaconda3/envs/venv_ilona/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Загрузка модели MobileNet\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)  # Заменяем последний слой для бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование GPU, если доступно\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=learning_rate, steps_per_epoch=len(train_loader), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.3807\n",
      "Validation Loss: 0.1014, Accuracy: 0.9510\n",
      "Epoch 2/3, Loss: 0.0439\n",
      "Validation Loss: 0.0494, Accuracy: 1.0000\n",
      "Epoch 3/3, Loss: 0.0169\n",
      "Validation Loss: 0.0130, Accuracy: 1.0000\n",
      "Обучение завершено\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = torch.sigmoid(outputs).round()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print('Обучение завершено')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet_v2.onnx\", input_names=[\"input\"], output_names=[\"output\"], opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ImageClassifierONNX:\n",
    "    def __init__(self, onnx_path):\n",
    "        self.onnx_session = ort.InferenceSession(onnx_path)\n",
    "        self.input_name = self.onnx_session.get_inputs()[0].name\n",
    "        self.output_name = self.onnx_session.get_outputs()[0].name\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).numpy()\n",
    "        outputs = self.onnx_session.run([self.output_name], {self.input_name: image})\n",
    "        output = outputs[0][0][0]\n",
    "        return output\n",
    "\n",
    "classifier_onnx = ImageClassifierONNX('mobilenet_v2.onnx')\n",
    "for path in os.listdir('../../data/classification_direction/val/bad/'):\n",
    "  result_onnx = classifier_onnx.predict(f'../../data/classification_direction/val/bad/{path}')\n",
    "  print(f'Результат классификации: {result_onnx:.4f}')\n",
    "\n",
    "print()\n",
    "for path in os.listdir('../../data/classification_direction/val/good/'):\n",
    "  result_onnx = classifier_onnx.predict(f'../../data/classification_direction/val/good/{path}')\n",
    "  print(f'Результат классификации: {result_onnx:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
