{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_root = '../../data/classification_direction'\n",
    "train_root = '../../data/classification_direction/train'\n",
    "val_root = '../../data/classification_direction/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import random\n",
    "# from shutil import copy2\n",
    "# from torchvision.datasets import ImageFolder\n",
    "\n",
    "# def create_dir_structure(root_path, classes):\n",
    "#     for cls in classes:\n",
    "#         os.makedirs(os.path.join(root_path, cls), exist_ok=True)\n",
    "\n",
    "# def copy_files(file_paths, source_root, target_root):\n",
    "#     for file_path in file_paths:\n",
    "#         class_name = os.path.basename(os.path.dirname(file_path))\n",
    "#         target_path = os.path.join(target_root, class_name, os.path.basename(file_path))\n",
    "#         copy2(file_path, target_path)\n",
    "\n",
    "# # Загрузка исходного датасета\n",
    "# dataset = ImageFolder(root=source_root)\n",
    "# class_names = dataset.classes\n",
    "\n",
    "# # Определим количество данных для тренировки и валидации\n",
    "# train_ratio = 0.8\n",
    "# total_size = len(dataset)\n",
    "# train_size = int(total_size * train_ratio)\n",
    "# val_size = total_size - train_size\n",
    "\n",
    "# # Перемешаем данные и разделим их\n",
    "# indices = list(range(total_size))\n",
    "# random.shuffle(indices)\n",
    "# train_indices, val_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "# train_files = [dataset.imgs[idx][0] for idx in train_indices]\n",
    "# val_files = [dataset.imgs[idx][0] for idx in val_indices]\n",
    "\n",
    "# # Создадим структуру папок для тренировочных и валидационных данных\n",
    "# create_dir_structure(train_root, class_names)\n",
    "# create_dir_structure(val_root, class_names)\n",
    "\n",
    "# # Скопируем файлы в соответствующие папки\n",
    "# copy_files(train_files, source_root, train_root)\n",
    "# copy_files(val_files, source_root, val_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "batch_size = 16\n",
    "num_epochs = 8\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Трансформации для данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "train_dataset = datasets.ImageFolder(root=train_root, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(root=val_root, transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели MobileNet\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)  # Заменяем последний слой для бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Использование GPU, если доступно\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь и оптимизатор\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8, Loss: 0.5531\n",
      "Validation Loss: 0.2681, Accuracy: 0.9333\n",
      "Epoch 2/8, Loss: 0.0826\n",
      "Validation Loss: 0.0867, Accuracy: 0.9333\n",
      "Epoch 3/8, Loss: 0.0572\n",
      "Validation Loss: 0.0669, Accuracy: 0.9333\n",
      "Epoch 4/8, Loss: 0.1482\n",
      "Validation Loss: 0.0147, Accuracy: 1.0000\n",
      "Epoch 5/8, Loss: 0.0133\n",
      "Validation Loss: 0.0203, Accuracy: 1.0000\n",
      "Epoch 6/8, Loss: 0.0038\n",
      "Validation Loss: 0.0272, Accuracy: 1.0000\n",
      "Epoch 7/8, Loss: 0.0136\n",
      "Validation Loss: 0.0218, Accuracy: 1.0000\n",
      "Epoch 8/8, Loss: 0.0156\n",
      "Validation Loss: 0.0092, Accuracy: 1.0000\n",
      "Обучение завершено\n"
     ]
    }
   ],
   "source": [
    "# Обучение модели\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "        \n",
    "        # Обнуление градиентов\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Прямой проход\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Обратный проход и оптимизация\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Оценка модели на валидационном наборе\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            predicted = torch.sigmoid(outputs).round()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "print('Обучение завершено')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена и экспортирована в формат ONNX\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Экспорт в формат ONNX\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "torch.onnx.export(model, dummy_input, \"mobilenet_v2.onnx\", input_names=[\"input\"], output_names=[\"output\"], opset_version=11)\n",
    "\n",
    "print(\"Модель сохранена и экспортирована в формат ONNX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ImageClassifierONNX:\n",
    "    def __init__(self, onnx_path):\n",
    "        self.onnx_session = ort.InferenceSession(onnx_path)\n",
    "        self.input_name = self.onnx_session.get_inputs()[0].name\n",
    "        self.output_name = self.onnx_session.get_outputs()[0].name\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def predict(self, image_path):\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image).unsqueeze(0).numpy()\n",
    "        outputs = self.onnx_session.run([self.output_name], {self.input_name: image})\n",
    "        output = outputs[0][0][0]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат классификации: -11.2225\n",
      "Результат классификации: -7.0359\n",
      "Результат классификации: -9.4938\n",
      "Результат классификации: -12.2561\n",
      "\n",
      "Результат классификации: 3.7085\n",
      "Результат классификации: 2.2994\n",
      "Результат классификации: 5.9101\n",
      "Результат классификации: 11.5769\n",
      "Результат классификации: 9.5283\n",
      "Результат классификации: 11.6647\n",
      "Результат классификации: 7.7167\n",
      "Результат классификации: 9.1278\n",
      "Результат классификации: 4.3042\n",
      "Результат классификации: 7.9933\n",
      "Результат классификации: 9.6085\n"
     ]
    }
   ],
   "source": [
    "classifier_onnx = ImageClassifierONNX('mobilenet_v2.onnx')\n",
    "for path in os.listdir('../../data/classification_direction/val/bad/'):\n",
    "  result_onnx = classifier_onnx.predict(f'../../data/classification_direction/val/bad/{path}')\n",
    "  print(f'Результат классификации: {result_onnx:.4f}')\n",
    "\n",
    "print()\n",
    "for path in os.listdir('../../data/classification_direction/val/good/'):\n",
    "  result_onnx = classifier_onnx.predict(f'../../data/classification_direction/val/good/{path}')\n",
    "  print(f'Результат классификации: {result_onnx:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
